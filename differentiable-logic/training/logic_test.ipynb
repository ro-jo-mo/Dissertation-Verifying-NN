{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from base.backends import TorchBackend\n",
    "from base.logic import Logic\n",
    "from base.dl2 import DL2\n",
    "from base.fuzzy_logics import *\n",
    "\n",
    "from training.constraints import *\n",
    "from training.models import *\n",
    "\n",
    "from training.group_definitions import gtsrb_groups, cifar10_groups\n",
    "\n",
    "from training.util import *\n",
    "from training.grad_norm import *\n",
    "from training.attacks import *\n",
    "\n",
    "EpochInfoTrain = namedtuple('EpochInfoTrain', 'pred_acc constr_acc constr_sec pred_loss random_loss constr_loss pred_loss_weight constr_loss_weight input_img adv_img random_img')\n",
    "EpochInfoTest = namedtuple('EpochInfoTest', 'pred_acc constr_acc constr_sec pred_loss random_loss constr_loss input_img adv_img random_img vacuously_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, device: torch.device, train_loader: torch.utils.data.DataLoader, optimizer, oracle: Attack, grad_norm: GradNorm, logic: Logic, constraint: Constraint, with_dl: bool) -> EpochInfoTrain:\n",
    "    avg_pred_acc, avg_pred_loss = torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "    avg_constr_acc, avg_constr_sec, avg_constr_loss, avg_random_loss = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "\n",
    "    images = { 'input': None, 'random': None, 'adv': None}\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader, start=1):\n",
    "        inputs, labels = data.to(device), target.to(device)\n",
    "\n",
    "        # forward pass for prediction accuracy\n",
    "        outputs = model(inputs)\n",
    "        ce_loss = F.cross_entropy(outputs, labels)\n",
    "        correct = torch.mean(torch.argmax(outputs, dim=1).eq(labels).float())\n",
    "\n",
    "        # get random + adversarial samples\n",
    "        with torch.no_grad():\n",
    "            random = oracle.uniform_random_sample(inputs)\n",
    "\n",
    "        adv = oracle.attack(model, inputs, labels, logic, constraint)\n",
    "\n",
    "        # forward pass for constraint accuracy (constraint satisfaction on random samples)\n",
    "        with torch.no_grad():\n",
    "            loss_random, sat_random = constraint.eval(model, inputs, random, labels, logic, reduction='mean')\n",
    "\n",
    "        # forward pass for constraint security (constraint satisfaction on adversarial samples)\n",
    "        with maybe(torch.no_grad(), not with_dl):\n",
    "            loss_adv, sat_adv = constraint.eval(model, inputs, adv, labels, logic, reduction='mean')\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if not with_dl:\n",
    "            ce_loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            grad_norm.balance(ce_loss, loss_adv)\n",
    "\n",
    "        avg_pred_acc += correct\n",
    "        avg_pred_loss += ce_loss\n",
    "        avg_constr_acc += sat_random\n",
    "        avg_constr_sec += sat_adv\n",
    "        avg_constr_loss += loss_adv\n",
    "        avg_random_loss += loss_random\n",
    "\n",
    "        # save one original image, random sample, and adversarial sample image (for debugging, inspecting attacks)\n",
    "        i = np.random.randint(0, inputs.size(0) - 1)\n",
    "        images['input'], images['random'], images['adv'] = inputs[i], random[i], adv[i]\n",
    "\n",
    "    if with_dl:\n",
    "        grad_norm.renormalise()\n",
    "\n",
    "    return EpochInfoTrain(\n",
    "        pred_acc=avg_pred_acc.item() / len(train_loader),\n",
    "        constr_acc=avg_constr_acc.item() / len(train_loader),\n",
    "        constr_sec=avg_constr_sec.item() / len(train_loader),\n",
    "        pred_loss=avg_pred_loss.item() / len(train_loader),\n",
    "        random_loss=avg_random_loss.item() / len(train_loader),\n",
    "        constr_loss=avg_constr_loss.item() / len(train_loader),\n",
    "        pred_loss_weight=grad_norm.weights[0].item(),\n",
    "        constr_loss_weight=grad_norm.weights[1].item(),\n",
    "        input_img=images['input'],\n",
    "        adv_img=images['adv'],\n",
    "        random_img=images['random']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: torch.nn.Module, device: torch.device, test_loader: torch.utils.data.DataLoader, oracle: Attack, logic: Logic, constraint: Constraint) -> EpochInfoTest:\n",
    "    correct, constr_acc, constr_sec = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "    avg_pred_loss, avg_constr_loss, avg_random_loss = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "\n",
    "    record_vacuously_true = isinstance(constraint, EvenOddConstraint) or isinstance(constraint, ClassSimilarityConstraint)\n",
    "\n",
    "    if record_vacuously_true:\n",
    "        vacuously_true = torch.zeros(2 if isinstance(constraint, EvenOddConstraint) else 10, device=device)\n",
    "\n",
    "    total_samples = 0\n",
    "\n",
    "    images = { 'input': None, 'random': None, 'adv': None}\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for _, (data, target) in enumerate(test_loader, start=1):\n",
    "        inputs, labels = data.to(device), target.to(device)\n",
    "        total_samples += inputs.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # forward pass for prediction accuracy\n",
    "            outputs = model(inputs)\n",
    "            avg_pred_loss += F.cross_entropy(outputs, labels, reduction='sum')\n",
    "            pred = outputs.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "            # get random samples (no grad)\n",
    "            random = oracle.uniform_random_sample(inputs)\n",
    "\n",
    "        # get adversarial samples (requires grad)\n",
    "        adv = oracle.attack(model, inputs, labels, logic, constraint)\n",
    "\n",
    "        # forward passes for constraint accuracy (constraint satisfaction on random samples) + constraint security (constraint satisfaction on adversarial samples)\n",
    "        with torch.no_grad():\n",
    "            loss_random, sat_random = constraint.eval(model, inputs, random, labels, logic, reduction='sum')\n",
    "            loss_adv, sat_adv = constraint.eval(model, inputs, adv, labels, logic, reduction='sum')\n",
    "\n",
    "            if record_vacuously_true:\n",
    "                vacuously_true += constraint.get_vacuously_true(model, adv)\n",
    "\n",
    "            constr_acc += sat_random\n",
    "            constr_sec += sat_adv\n",
    "\n",
    "            avg_random_loss += loss_random\n",
    "            avg_constr_loss += loss_adv\n",
    "\n",
    "        # save one original image, random sample, and adversarial sample image (for debugging, inspecting attacks)\n",
    "        i = np.random.randint(0, inputs.size(0) - 1)\n",
    "        images['input'], images['random'], images['adv'] = inputs[i], random[i], adv[i]\n",
    "\n",
    "    return EpochInfoTest(\n",
    "        pred_acc=correct.item() / total_samples, \n",
    "        constr_acc=constr_acc.item() / total_samples,\n",
    "        constr_sec=constr_sec.item() / total_samples,\n",
    "        pred_loss=avg_pred_loss.item() / total_samples,\n",
    "        random_loss=avg_random_loss.item() / total_samples,\n",
    "        constr_loss=avg_constr_loss.item() / total_samples,\n",
    "        input_img=images['input'],\n",
    "        adv_img=images['adv'],\n",
    "        random_img=images['random'],\n",
    "        vacuously_true=(vacuously_true / total_samples) if record_vacuously_true else -1.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = TorchBackend()\n",
    "\n",
    "logics: list[Logic] = [\n",
    "    DL2(backend),\n",
    "    GoedelFuzzyLogic(backend),\n",
    "    KleeneDienesFuzzyLogic(backend),\n",
    "    LukasiewiczFuzzyLogic(backend),\n",
    "    ReichenbachFuzzyLogic(backend),\n",
    "    GoguenFuzzyLogic(backend),\n",
    "    ReichenbachSigmoidalFuzzyLogic(backend),\n",
    "    YagerFuzzyLogic(backend)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = [3,3,3,3,3,3,2,3,3,4,4,1,0,0,0,4,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,5,5,5,5,5,5,5,5,2,2]\n",
    "GROUP_NAMES = [\"Unique Signs\",\"Danger Signs\",\"Derestriction Signs\",\"Speed Limit Signs\",\"Other Prohibitory Signs\",\"Mandatory Signs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N = 32\n",
    "batch_size = 128\n",
    "n_classes = 43\n",
    "epochs = 30\n",
    "kwargs = {\"batch_size\": batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.deterministic = False #True\n",
    "    torch.backends.cudnn.benchmark = True #False\n",
    "\n",
    "    kwargs.update({ 'num_workers': 4, 'pin_memory': True })\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.3211\n",
    "std = 0.2230\n",
    "\n",
    "def to_image(img): # convert to unormalized form for viewing\n",
    "\n",
    "    return (img * std + mean).permute(1,2,0).numpy()\n",
    "\n",
    "normalise = transforms.Normalize(mean, std)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((_N,_N)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(),\n",
    "    normalise\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root=\"/home/rob/code/Project/dataset/GTSRB/Training\", transform=transform)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.8,0.2])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           num_workers=6,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True\n",
    "                                           )\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          num_workers=6,\n",
    "                                          shuffle=False,\n",
    "                                          drop_last=True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        x = torch.zeros((64,1,_N,_N))\n",
    "\n",
    "        self.activation = torch.nn.functional.relu\n",
    "\n",
    "        self.pool = torch.nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1,6,5)\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(x.shape[1],16,5)\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        self.dense1 = torch.nn.Linear(x.shape[1],128)\n",
    "        x = self.activation(self.dense1(x))\n",
    "        self.dense2 = torch.nn.Linear(x.shape[1],64)\n",
    "        x = self.activation(self.dense2(x))\n",
    "        self.final = torch.nn.Linear(x.shape[1],n_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.activation(self.dense1(x))\n",
    "        x = self.activation(self.dense2(x))\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint.eps=0.062745101749897\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logic = logics[0] # need some logic loss for oracle even for baseline\n",
    "is_baseline = True\n",
    "\n",
    "epsilon = 16 / 255\n",
    "delta = 0.02\n",
    "\n",
    "constraint = GroupConstraint(device, epsilon, delta, gtsrb_groups)\n",
    "print(f'constraint.eps={constraint.eps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "pgd_iterations = 20\n",
    "pgd_restarts = 10\n",
    "oracle = APGD(device, pgd_iterations, pgd_restarts, mean, std, constraint.eps)\n",
    "oracle_test = APGD(device, pgd_iterations * 2, pgd_restarts, mean, std, constraint.eps)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "grad_norm = GradNorm(model, device, optimizer, lr=0.001, alpha=0.12, initial_dl_weight=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "#model parameters: 64951\n"
     ]
    }
   ],
   "source": [
    "folder = \"abcd\"\n",
    "folder_name = \"abcd\"\n",
    "file_name = \"abcd/test\"\n",
    "report_file_name = f'{file_name}.csv'\n",
    "model_file_name = f'{file_name}.onnx'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "def save_imgs(info: EpochInfoTrain | EpochInfoTest, epoch):\n",
    "    return\n",
    "print(f'using device {device}')\n",
    "print(f'#model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "with_extra_info = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30 \t TRAIN \t P-Acc: 0.00 \t C-Acc: 0.00\t C-Sec: 0.00\t P-Loss: 0.00\t R-Loss: 0.00\t DL-Loss: 0.00\t Time (Train) [s]: 0.0\n",
      "===\n",
      "GradNorm weights=tensor([0.9518, 1.0482])\n",
      "Epoch 1/30 \t TRAIN \t P-Acc: 0.33 \t C-Acc: 0.06\t C-Sec: 0.05\t P-Loss: 2.45\t R-Loss: 0.46\t DL-Loss: 0.61\t Time (Train) [s]: 295.4\n",
      "Epoch 1/30 \t TRAIN \t P-Acc: 0.33 \t C-Acc: 0.06\t C-Sec: 0.05\t P-Loss: 2.45\t R-Loss: 0.46\t DL-Loss: 0.61\t Time (Train) [s]: 295.4\n",
      "===\n",
      "GradNorm weights=tensor([0.9510, 1.0490])\n",
      "Epoch 2/30 \t TRAIN \t P-Acc: 0.77 \t C-Acc: 0.50\t C-Sec: 0.41\t P-Loss: 0.78\t R-Loss: 0.11\t DL-Loss: 0.31\t Time (Train) [s]: 366.3\n",
      "Epoch 2/30 \t TRAIN \t P-Acc: 0.77 \t C-Acc: 0.50\t C-Sec: 0.41\t P-Loss: 0.78\t R-Loss: 0.11\t DL-Loss: 0.31\t Time (Train) [s]: 366.3\n",
      "===\n",
      "GradNorm weights=tensor([0.9635, 1.0365])\n",
      "Epoch 3/30 \t TRAIN \t P-Acc: 0.86 \t C-Acc: 0.71\t C-Sec: 0.59\t P-Loss: 0.50\t R-Loss: 0.06\t DL-Loss: 0.18\t Time (Train) [s]: 311.9\n",
      "Epoch 3/30 \t TRAIN \t P-Acc: 0.86 \t C-Acc: 0.71\t C-Sec: 0.59\t P-Loss: 0.50\t R-Loss: 0.06\t DL-Loss: 0.18\t Time (Train) [s]: 311.9\n",
      "===\n",
      "GradNorm weights=tensor([0.9566, 1.0434])\n",
      "Epoch 4/30 \t TRAIN \t P-Acc: 0.89 \t C-Acc: 0.79\t C-Sec: 0.66\t P-Loss: 0.37\t R-Loss: 0.04\t DL-Loss: 0.14\t Time (Train) [s]: 288.4\n",
      "Epoch 4/30 \t TRAIN \t P-Acc: 0.89 \t C-Acc: 0.79\t C-Sec: 0.66\t P-Loss: 0.37\t R-Loss: 0.04\t DL-Loss: 0.14\t Time (Train) [s]: 288.4\n",
      "===\n",
      "GradNorm weights=tensor([0.9577, 1.0423])\n",
      "Epoch 5/30 \t TRAIN \t P-Acc: 0.92 \t C-Acc: 0.83\t C-Sec: 0.71\t P-Loss: 0.30\t R-Loss: 0.03\t DL-Loss: 0.11\t Time (Train) [s]: 290.0\n",
      "Epoch 5/30 \t TRAIN \t P-Acc: 0.92 \t C-Acc: 0.83\t C-Sec: 0.71\t P-Loss: 0.30\t R-Loss: 0.03\t DL-Loss: 0.11\t Time (Train) [s]: 290.0\n",
      "===\n",
      "GradNorm weights=tensor([0.9524, 1.0476])\n",
      "Epoch 6/30 \t TRAIN \t P-Acc: 0.93 \t C-Acc: 0.86\t C-Sec: 0.75\t P-Loss: 0.24\t R-Loss: 0.03\t DL-Loss: 0.09\t Time (Train) [s]: 292.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_info \u001b[38;5;241m=\u001b[39m EpochInfoTrain(\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m     train_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m---> 21\u001b[0m test_info \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moracle_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m test_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start \u001b[38;5;241m-\u001b[39m train_time\n\u001b[1;32m     24\u001b[0m save_imgs(test_info, epoch)\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, oracle, logic, constraint)\u001b[0m\n\u001b[1;32m     28\u001b[0m     random \u001b[38;5;241m=\u001b[39m oracle\u001b[38;5;241m.\u001b[39muniform_random_sample(inputs)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# get adversarial samples (requires grad)\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m adv \u001b[38;5;241m=\u001b[39m \u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# forward passes for constraint accuracy (constraint satisfaction on random samples) + constraint security (constraint satisfaction on adversarial samples)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/code/Project/differentiable-logic/training/../training/attacks.py:224\u001b[0m, in \u001b[0;36mAPGD.attack\u001b[0;34m(self, model, x, y, logic, constraint)\u001b[0m\n\u001b[1;32m    221\u001b[0m loss_best \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarts \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 224\u001b[0m     best_curr, loss_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     i \u001b[38;5;241m=\u001b[39m (loss_curr \u001b[38;5;241m>\u001b[39m loss_best)\u001b[38;5;241m.\u001b[39mnonzero()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    227\u001b[0m     adv_best[i] \u001b[38;5;241m=\u001b[39m best_curr[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.\u001b[39m\n",
      "File \u001b[0;32m~/code/Project/differentiable-logic/training/../training/attacks.py:175\u001b[0m, in \u001b[0;36mAPGD.attack_single\u001b[0;34m(self, model, x, y, logic, constraint)\u001b[0m\n\u001b[1;32m    172\u001b[0m         loss_indiv, _ \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39meval(model, x, x_adv, y, logic, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, skip_sat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    173\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_indiv\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m--> 175\u001b[0m     grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    177\u001b[0m grad \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meot_iter)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/code/Project/pytorchenv/lib/python3.10/site-packages/torch/autograd/__init__.py:412\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    408\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    409\u001b[0m         grad_outputs_\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    423\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    425\u001b[0m     ):\n",
      "File \u001b[0;32m~/code/Project/pytorchenv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(report_file_name, 'w', buffering=1, newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    csvfile.write(f'#{sys.argv}\\n')\n",
    "    writer.writerow(['Epoch', 'Train-P-Loss', 'Train-R-Loss', 'Train-C-Loss', 'Train-P-Loss-Weight', 'Train-C-Loss-Weight', 'Train-P-Acc', 'Train-C-Acc', 'Train-C-Sec', 'Test-P-Acc', 'Test-C-Acc', 'Test-C-Sec', 'Train-Time', 'Test-Time'])\n",
    "\n",
    "    for epoch in range(0, epochs + 1):\n",
    "        start = time.time()\n",
    "\n",
    "        if epoch > 0:\n",
    "            with_dl = True # (epoch > args.delay) and (not is_baseline)\n",
    "            train_info = train(model, device, train_loader, optimizer, oracle, grad_norm, logic, constraint, with_dl)\n",
    "            train_time = time.time() - start\n",
    "\n",
    "            save_imgs(train_info, epoch)\n",
    "\n",
    "            print(f'Epoch {epoch}/{epochs} \\t TRAIN \\t P-Acc: {train_info.pred_acc:.2f} \\t C-Acc: {train_info.constr_acc:.2f}\\t C-Sec: {train_info.constr_sec:.2f}\\t P-Loss: {train_info.pred_loss:.2f}\\t R-Loss: {train_info.random_loss:.2f}\\t DL-Loss: {train_info.constr_loss:.2f}\\t Time (Train) [s]: {train_time:.1f}')\n",
    "        else:\n",
    "            train_info = EpochInfoTrain(0., 0., 0., 0., 0., 0., 1., 1., None, None, None)\n",
    "            train_time = 0.\n",
    "\n",
    "        test_info = test(model, device, test_loader, oracle_test, logic, constraint)\n",
    "        test_time = time.time() - start - train_time\n",
    "\n",
    "        save_imgs(test_info, epoch)\n",
    "\n",
    "        writer.writerow([epoch, \\\n",
    "                            train_info.pred_loss, train_info.random_loss, train_info.constr_loss, train_info.pred_loss_weight, train_info.constr_loss_weight, train_info.pred_acc, train_info.constr_acc, train_info.constr_sec, \\\n",
    "                            test_info.pred_acc, test_info.constr_acc, test_info.constr_sec, \\\n",
    "                            train_time, test_time] \\\n",
    "                        + ([v.item() for v in test_info.vacuously_true] if with_extra_info else []))\n",
    "\n",
    "        if with_extra_info:\n",
    "            print(f'impl vacuously true=[{\" \".join([f\"{x:.2f}\" for x in test_info.vacuously_true])}]')\n",
    "\n",
    "        print(f'Epoch {epoch}/{epochs} \\t TRAIN \\t P-Acc: {train_info.pred_acc:.2f} \\t C-Acc: {train_info.constr_acc:.2f}\\t C-Sec: {train_info.constr_sec:.2f}\\t P-Loss: {train_info.pred_loss:.2f}\\t R-Loss: {train_info.random_loss:.2f}\\t DL-Loss: {train_info.constr_loss:.2f}\\t Time (Train) [s]: {train_time:.1f}')\n",
    "        print(f'===')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
