{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from base.backends import TorchBackend\n",
    "from base.logic import Logic\n",
    "from base.dl2 import DL2\n",
    "from base.fuzzy_logics import *\n",
    "\n",
    "from training.constraints import *\n",
    "from training.models import *\n",
    "\n",
    "from training.group_definitions import gtsrb_groups, cifar10_groups\n",
    "\n",
    "from training.util import *\n",
    "from training.grad_norm import *\n",
    "from training.attacks import *\n",
    "\n",
    "EpochInfoTrain = namedtuple('EpochInfoTrain', 'pred_acc constr_acc constr_sec pred_loss random_loss constr_loss pred_loss_weight constr_loss_weight input_img adv_img random_img')\n",
    "EpochInfoTest = namedtuple('EpochInfoTest', 'pred_acc constr_acc constr_sec pred_loss random_loss constr_loss input_img adv_img random_img vacuously_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, device: torch.device, train_loader: torch.utils.data.DataLoader, optimizer, oracle: Attack, grad_norm: GradNorm, logic: Logic, constraint: Constraint, with_dl: bool) -> EpochInfoTrain:\n",
    "    avg_pred_acc, avg_pred_loss = torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "    avg_constr_acc, avg_constr_sec, avg_constr_loss, avg_random_loss = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "\n",
    "    images = { 'input': None, 'random': None, 'adv': None}\n",
    "\n",
    "    model.train()\n",
    "    abc = 0\n",
    "    for _, (data, target) in enumerate(train_loader, start=1):\n",
    "        inputs, labels = data.to(device), target.to(device)\n",
    "        print(f\"Batch: {abc}\")\n",
    "        abc += 1\n",
    "        # forward pass for prediction accuracy\n",
    "        outputs = model(inputs)\n",
    "        ce_loss = F.cross_entropy(outputs, labels)\n",
    "        correct = torch.mean(torch.argmax(outputs, dim=1).eq(labels).float())\n",
    "\n",
    "        # get random + adversarial samples\n",
    "        with torch.no_grad():\n",
    "            random = oracle.uniform_random_sample(inputs)\n",
    "\n",
    "        adv = oracle.attack(model, inputs, labels, logic, constraint)\n",
    "\n",
    "        # forward pass for constraint accuracy (constraint satisfaction on random samples)\n",
    "        with torch.no_grad():\n",
    "            loss_random, sat_random = constraint.eval(model, inputs, random, labels, logic, reduction='mean')\n",
    "\n",
    "        # forward pass for constraint security (constraint satisfaction on adversarial samples)\n",
    "        with maybe(torch.no_grad(), not with_dl):\n",
    "            loss_adv, sat_adv = constraint.eval(model, inputs, adv, labels, logic, reduction='mean')\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if not with_dl:\n",
    "            ce_loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            grad_norm.balance(ce_loss, loss_adv)\n",
    "\n",
    "        avg_pred_acc += correct\n",
    "        avg_pred_loss += ce_loss\n",
    "        avg_constr_acc += sat_random\n",
    "        avg_constr_sec += sat_adv\n",
    "        avg_constr_loss += loss_adv\n",
    "        avg_random_loss += loss_random\n",
    "\n",
    "        # save one original image, random sample, and adversarial sample image (for debugging, inspecting attacks)\n",
    "        i = np.random.randint(0, inputs.size(0) - 1)\n",
    "        images['input'], images['random'], images['adv'] = inputs[i], random[i], adv[i]\n",
    "\n",
    "\n",
    "    if with_dl:\n",
    "        grad_norm.renormalise()\n",
    "\n",
    "    return EpochInfoTrain(\n",
    "        pred_acc=avg_pred_acc.item() / len(train_loader),\n",
    "        constr_acc=avg_constr_acc.item() / len(train_loader),\n",
    "        constr_sec=avg_constr_sec.item() / len(train_loader),\n",
    "        pred_loss=avg_pred_loss.item() / len(train_loader),\n",
    "        random_loss=avg_random_loss.item() / len(train_loader),\n",
    "        constr_loss=avg_constr_loss.item() / len(train_loader),\n",
    "        pred_loss_weight=grad_norm.weights[0].item(),\n",
    "        constr_loss_weight=grad_norm.weights[1].item(),\n",
    "        input_img=images['input'],\n",
    "        adv_img=images['adv'],\n",
    "        random_img=images['random']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: torch.nn.Module, device: torch.device, test_loader: torch.utils.data.DataLoader, oracle: Attack, logic: Logic, constraint: Constraint) -> EpochInfoTest:\n",
    "    correct, constr_acc, constr_sec = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "    avg_pred_loss, avg_constr_loss, avg_random_loss = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "\n",
    "    record_vacuously_true = isinstance(constraint, EvenOddConstraint) or isinstance(constraint, ClassSimilarityConstraint)\n",
    "\n",
    "    if record_vacuously_true:\n",
    "        vacuously_true = torch.zeros(2 if isinstance(constraint, EvenOddConstraint) else 10, device=device)\n",
    "\n",
    "    total_samples = 0\n",
    "\n",
    "    images = { 'input': None, 'random': None, 'adv': None}\n",
    "\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    for _, (data, target) in enumerate(test_loader, start=1):\n",
    "        inputs, labels = data.to(device), target.to(device)\n",
    "        print(f\"test batch: {counter}\")\n",
    "        counter += 1\n",
    "        total_samples += inputs.size(0)\n",
    "        print(\"1\")\n",
    "        with torch.no_grad():\n",
    "            # forward pass for prediction accuracy\n",
    "            outputs = model(inputs)\n",
    "            avg_pred_loss += F.cross_entropy(outputs, labels, reduction='sum')\n",
    "            pred = outputs.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "            # get random samples (no grad)\n",
    "            random = oracle.uniform_random_sample(inputs)\n",
    "        print(\"2\")\n",
    "        # get adversarial samples (requires grad)\n",
    "        adv = oracle.attack(model, inputs, labels, logic, constraint)\n",
    "        print(\"3\")\n",
    "        # forward passes for constraint accuracy (constraint satisfaction on random samples) + constraint security (constraint satisfaction on adversarial samples)\n",
    "        with torch.no_grad():\n",
    "            loss_random, sat_random = constraint.eval(model, inputs, random, labels, logic, reduction='sum')\n",
    "            loss_adv, sat_adv = constraint.eval(model, inputs, adv, labels, logic, reduction='sum')\n",
    "\n",
    "            if record_vacuously_true:\n",
    "                vacuously_true += constraint.get_vacuously_true(model, adv)\n",
    "\n",
    "            constr_acc += sat_random\n",
    "            constr_sec += sat_adv\n",
    "\n",
    "            avg_random_loss += loss_random\n",
    "            avg_constr_loss += loss_adv\n",
    "        print(\"4\")\n",
    "        # save one original image, random sample, and adversarial sample image (for debugging, inspecting attacks)\n",
    "        i = np.random.randint(0, inputs.size(0) - 1)\n",
    "        images['input'], images['random'], images['adv'] = inputs[i], random[i], adv[i]\n",
    "\n",
    "    return EpochInfoTest(\n",
    "        pred_acc=correct.item() / total_samples, \n",
    "        constr_acc=constr_acc.item() / total_samples,\n",
    "        constr_sec=constr_sec.item() / total_samples,\n",
    "        pred_loss=avg_pred_loss.item() / total_samples,\n",
    "        random_loss=avg_random_loss.item() / total_samples,\n",
    "        constr_loss=avg_constr_loss.item() / total_samples,\n",
    "        input_img=images['input'],\n",
    "        adv_img=images['adv'],\n",
    "        random_img=images['random'],\n",
    "        vacuously_true=(vacuously_true / total_samples) if record_vacuously_true else -1.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = TorchBackend()\n",
    "\n",
    "logics: list[Logic] = [\n",
    "    DL2(backend),\n",
    "    GoedelFuzzyLogic(backend),\n",
    "    KleeneDienesFuzzyLogic(backend),\n",
    "    LukasiewiczFuzzyLogic(backend),\n",
    "    ReichenbachFuzzyLogic(backend),\n",
    "    GoguenFuzzyLogic(backend),\n",
    "    ReichenbachSigmoidalFuzzyLogic(backend),\n",
    "    YagerFuzzyLogic(backend)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = [3,3,3,3,3,3,2,3,3,4,4,1,0,0,0,4,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,5,5,5,5,5,5,5,5,2,2]\n",
    "GROUP_NAMES = [\"Unique Signs\",\"Danger Signs\",\"Derestriction Signs\",\"Speed Limit Signs\",\"Other Prohibitory Signs\",\"Mandatory Signs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N = 32\n",
    "batch_size = 128\n",
    "n_classes = 12\n",
    "epochs = 30\n",
    "kwargs = {\"batch_size\": batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_data\n",
    "PATH,LABELS,normalise,GROUPS,GROUP_NAMES,n_classes,train_loader,test_loader = get_data(32,128)\n",
    "mean = 0.3211\n",
    "std = 0.2230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    kwargs.update({ 'num_workers': 4, 'pin_memory': True })\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device = torch.device('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        x = torch.zeros((64,1,_N,_N))\n",
    "\n",
    "        self.activation = torch.nn.functional.relu\n",
    "\n",
    "        self.pool = torch.nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1,6,5)\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(x.shape[1],16,5)\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        self.dense1 = torch.nn.Linear(x.shape[1],120)\n",
    "        x = self.activation(self.dense1(x))\n",
    "        self.dense2 = torch.nn.Linear(x.shape[1],80)\n",
    "        x = self.activation(self.dense2(x))\n",
    "        self.final = torch.nn.Linear(x.shape[1],n_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.activation(self.dense1(x))\n",
    "        x = self.activation(self.dense2(x))\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint.eps=0.062745101749897\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logic = logics[1] # need some logic loss for oracle even for baseline\n",
    "is_baseline = True\n",
    "\n",
    "epsilon = 16 / 255\n",
    "delta = 0.02\n",
    "\n",
    "constraint = MyConstraint(device,epsilon)\n",
    "print(f'constraint.eps={constraint.eps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "pgd_iterations = 20\n",
    "pgd_restarts = 10\n",
    "oracle = APGD(device, pgd_iterations, pgd_restarts, mean, std, constraint.eps)\n",
    "oracle_test = APGD(device, pgd_iterations * 2, pgd_restarts, mean, std, constraint.eps)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "grad_norm = GradNorm(model, device, optimizer, lr=0.001, alpha=0.12, initial_dl_weight=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "#model parameters: 61344\n"
     ]
    }
   ],
   "source": [
    "folder = \"abcd\"\n",
    "folder_name = \"abcd\"\n",
    "file_name = \"abcd/test\"\n",
    "report_file_name = f'{file_name}.csv'\n",
    "model_file_name = f'{file_name}.onnx'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "def save_imgs(info: EpochInfoTrain | EpochInfoTest, epoch):\n",
    "    return\n",
    "print(f'using device {device}')\n",
    "print(f'#model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "with_extra_info = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAA\n",
      "BBB\n",
      "test batch: 0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "test batch: 1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "test batch: 2\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     train_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBBB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m test_info \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moracle_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m test_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start \u001b[38;5;241m-\u001b[39m train_time\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCCC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, oracle, logic, constraint)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# get adversarial samples (requires grad)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m adv \u001b[38;5;241m=\u001b[39m \u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# forward passes for constraint accuracy (constraint satisfaction on random samples) + constraint security (constraint satisfaction on adversarial samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/code/Project/differentiable-logic/training/../training/attacks.py:224\u001b[0m, in \u001b[0;36mAPGD.attack\u001b[0;34m(self, model, x, y, logic, constraint)\u001b[0m\n\u001b[1;32m    221\u001b[0m loss_best \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarts \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 224\u001b[0m     best_curr, loss_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     i \u001b[38;5;241m=\u001b[39m (loss_curr \u001b[38;5;241m>\u001b[39m loss_best)\u001b[38;5;241m.\u001b[39mnonzero()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    227\u001b[0m     adv_best[i] \u001b[38;5;241m=\u001b[39m best_curr[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.\u001b[39m\n",
      "File \u001b[0;32m~/code/Project/differentiable-logic/training/../training/attacks.py:172\u001b[0m, in \u001b[0;36mAPGD.attack_single\u001b[0;34m(self, model, x, y, logic, constraint)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meot_iter):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 172\u001b[0m         loss_indiv, _ \u001b[38;5;241m=\u001b[39m \u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_sat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_indiv\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    175\u001b[0m     grad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(loss, [x_adv])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/code/Project/differentiable-logic/training/../training/constraints.py:39\u001b[0m, in \u001b[0;36mConstraint.eval\u001b[0;34m(self, model, inputs, adv, labels, logic, reduction, skip_sat)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, inputs: torch\u001b[38;5;241m.\u001b[39mTensor, adv: torch\u001b[38;5;241m.\u001b[39mTensor, labels: torch\u001b[38;5;241m.\u001b[39mTensor, logic: Logic, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, skip_sat: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m---> 39\u001b[0m     constraint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_constraint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     loss, sat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     loss \u001b[38;5;241m=\u001b[39m constraint(logic)\n",
      "File \u001b[0;32m~/code/Project/differentiable-logic/training/../training/constraints.py:174\u001b[0m, in \u001b[0;36mMyConstraint.get_constraint\u001b[0;34m(self, model, _inputs, adv, _labels)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m             out_of_group[batch_index,out_counter] \u001b[38;5;241m=\u001b[39m pred[label]\n\u001b[0;32m--> 174\u001b[0m             out_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m l: reduce(\n\u001b[1;32m    176\u001b[0m         l\u001b[38;5;241m.\u001b[39mAND,\n\u001b[1;32m    177\u001b[0m         [\n\u001b[1;32m    178\u001b[0m             l\u001b[38;5;241m.\u001b[39mLEQ(out_of_group[:,j], in_group[:,i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m    179\u001b[0m         ]\n\u001b[1;32m    180\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(report_file_name, 'w', buffering=1, newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    csvfile.write(f'#{sys.argv}\\n')\n",
    "    writer.writerow(['Epoch', 'Train-P-Loss', 'Train-R-Loss', 'Train-C-Loss', 'Train-P-Loss-Weight', 'Train-C-Loss-Weight', 'Train-P-Acc', 'Train-C-Acc', 'Train-C-Sec', 'Test-P-Acc', 'Test-C-Acc', 'Test-C-Sec', 'Train-Time', 'Test-Time'])\n",
    "\n",
    "    for epoch in range(0, epochs + 1):\n",
    "        start = time.time()\n",
    "        print(\"AAAA\")\n",
    "        if epoch > 0:\n",
    "            with_dl = True # (epoch > args.delay) and (not is_baseline)\n",
    "            train_info = train(model, device, train_loader, optimizer, oracle, grad_norm, logic, constraint, with_dl)\n",
    "            train_time = time.time() - start\n",
    "\n",
    "            save_imgs(train_info, epoch)\n",
    "\n",
    "            print(f'Epoch {epoch}/{epochs} \\t TRAIN \\t P-Acc: {train_info.pred_acc:.2f} \\t C-Acc: {train_info.constr_acc:.2f}\\t C-Sec: {train_info.constr_sec:.2f}\\t P-Loss: {train_info.pred_loss:.2f}\\t R-Loss: {train_info.random_loss:.2f}\\t DL-Loss: {train_info.constr_loss:.2f}\\t Time (Train) [s]: {train_time:.1f}')\n",
    "        else:\n",
    "            train_info = EpochInfoTrain(0., 0., 0., 0., 0., 0., 1., 1., None, None, None)\n",
    "            train_time = 0.\n",
    "        print(\"BBB\")\n",
    "        test_info = test(model, device, test_loader, oracle_test, logic, constraint)\n",
    "        test_time = time.time() - start - train_time\n",
    "        print(\"CCCC\")\n",
    "        save_imgs(test_info, epoch)\n",
    "\n",
    "        writer.writerow([epoch, \\\n",
    "                            train_info.pred_loss, train_info.random_loss, train_info.constr_loss, train_info.pred_loss_weight, train_info.constr_loss_weight, train_info.pred_acc, train_info.constr_acc, train_info.constr_sec, \\\n",
    "                            test_info.pred_acc, test_info.constr_acc, test_info.constr_sec, \\\n",
    "                            train_time, test_time] \\\n",
    "                        + ([v.item() for v in test_info.vacuously_true] if with_extra_info else []))\n",
    "        \n",
    "        if with_extra_info:\n",
    "            print(f'impl vacuously true=[{\" \".join([f\"{x:.2f}\" for x in test_info.vacuously_true])}]')\n",
    "\n",
    "        print(f'Epoch {epoch}/{epochs} \\t TRAIN \\t P-Acc: {train_info.pred_acc:.2f} \\t C-Acc: {train_info.constr_acc:.2f}\\t C-Sec: {train_info.constr_sec:.2f}\\t P-Loss: {train_info.pred_loss:.2f}\\t R-Loss: {train_info.random_loss:.2f}\\t DL-Loss: {train_info.constr_loss:.2f}\\t Time (Train) [s]: {train_time:.1f}')\n",
    "        print(f'===')\n",
    "torch.save(model.state_dict(),f\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraint(self, model: torch.nn.Module, _inputs: None, adv: torch.Tensor, _labels: None) -> Callable[[Logic], torch.Tensor]:\n",
    "        predictions = model(adv)\n",
    "        GROUPS = [1, 1, 2, 2, 1, 0, 0, 0, 2, 2, 0, 1]\n",
    "        batch_size = len(adv)\n",
    "        in_group = torch.zeros((batch_size,4)).to(self.device)\n",
    "        out_of_group = torch.zeros((batch_size,8)).to(self.device)\n",
    "        \n",
    "        for batch_index,pred in enumerate(predictions):\n",
    "            correct_group = GROUPS[_labels[batch_index]]\n",
    "            in_counter = 0\n",
    "            out_counter = 0\n",
    "            for label,group in enumerate(GROUPS):\n",
    "                if group == correct_group:\n",
    "                    in_group[batch_index,in_counter] = pred[label]\n",
    "                    in_counter += 1\n",
    "                else:\n",
    "                    out_of_group[batch_index,out_counter] = pred[label]\n",
    "                    out_counter += 1\n",
    "        return lambda l: reduce(\n",
    "                l.AND,\n",
    "                [\n",
    "                    l.LEQ(out_of_group[:,j], in_group[:,i]) for i in range(4) for j in range(8)\n",
    "                ]\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
