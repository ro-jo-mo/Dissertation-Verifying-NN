{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import argparse\n",
    "\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import onnx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from base.backends import TorchBackend\n",
    "from base.logic import Logic\n",
    "from base.dl2 import DL2\n",
    "from base.fuzzy_logics import *\n",
    "\n",
    "from training.constraints import *\n",
    "from training.models import *\n",
    "\n",
    "from training.group_definitions import gtsrb_groups, cifar10_groups\n",
    "\n",
    "from training.util import *\n",
    "from training.grad_norm import *\n",
    "from training.attacks import *\n",
    "\n",
    "EpochInfoTrain = namedtuple('EpochInfoTrain', 'pred_acc constr_acc constr_sec pred_loss random_loss constr_loss pred_loss_weight constr_loss_weight input_img adv_img random_img')\n",
    "EpochInfoTest = namedtuple('EpochInfoTest', 'pred_acc constr_acc constr_sec pred_loss random_loss constr_loss input_img adv_img random_img vacuously_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module, device: torch.device, train_loader: torch.utils.data.DataLoader, optimizer, oracle: Attack, grad_norm: GradNorm, logic: Logic, constraint: Constraint, with_dl: bool) -> EpochInfoTrain:\n",
    "    avg_pred_acc, avg_pred_loss = torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "    avg_constr_acc, avg_constr_sec, avg_constr_loss, avg_random_loss = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "\n",
    "    images = { 'input': None, 'random': None, 'adv': None}\n",
    "\n",
    "    model.train()\n",
    "    abc = 0\n",
    "    for _, (data, target) in enumerate(train_loader, start=1):\n",
    "        inputs, labels = data.to(device), target.to(device)\n",
    "        print(f\"Batch: {abc}\")\n",
    "        abc += 1\n",
    "        # forward pass for prediction accuracy\n",
    "        outputs = model(inputs)\n",
    "        ce_loss = F.cross_entropy(outputs, labels)\n",
    "        correct = torch.mean(torch.argmax(outputs, dim=1).eq(labels).float())\n",
    "\n",
    "        # get random + adversarial samples\n",
    "        with torch.no_grad():\n",
    "            random = oracle.uniform_random_sample(inputs)\n",
    "\n",
    "        adv = oracle.attack(model, inputs, labels, logic, constraint)\n",
    "\n",
    "        # forward pass for constraint accuracy (constraint satisfaction on random samples)\n",
    "        with torch.no_grad():\n",
    "            loss_random, sat_random = constraint.eval(model, inputs, random, labels, logic, reduction='mean')\n",
    "\n",
    "        # forward pass for constraint security (constraint satisfaction on adversarial samples)\n",
    "        with maybe(torch.no_grad(), not with_dl):\n",
    "            loss_adv, sat_adv = constraint.eval(model, inputs, adv, labels, logic, reduction='mean')\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if not with_dl:\n",
    "            ce_loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            grad_norm.balance(ce_loss, loss_adv)\n",
    "\n",
    "        avg_pred_acc += correct\n",
    "        avg_pred_loss += ce_loss\n",
    "        avg_constr_acc += sat_random\n",
    "        avg_constr_sec += sat_adv\n",
    "        avg_constr_loss += loss_adv\n",
    "        avg_random_loss += loss_random\n",
    "\n",
    "        # save one original image, random sample, and adversarial sample image (for debugging, inspecting attacks)\n",
    "        i = np.random.randint(0, inputs.size(0) - 1)\n",
    "        images['input'], images['random'], images['adv'] = inputs[i], random[i], adv[i]\n",
    "\n",
    "\n",
    "    if with_dl:\n",
    "        grad_norm.renormalise()\n",
    "\n",
    "    return EpochInfoTrain(\n",
    "        pred_acc=avg_pred_acc.item() / len(train_loader),\n",
    "        constr_acc=avg_constr_acc.item() / len(train_loader),\n",
    "        constr_sec=avg_constr_sec.item() / len(train_loader),\n",
    "        pred_loss=avg_pred_loss.item() / len(train_loader),\n",
    "        random_loss=avg_random_loss.item() / len(train_loader),\n",
    "        constr_loss=avg_constr_loss.item() / len(train_loader),\n",
    "        pred_loss_weight=grad_norm.weights[0].item(),\n",
    "        constr_loss_weight=grad_norm.weights[1].item(),\n",
    "        input_img=images['input'],\n",
    "        adv_img=images['adv'],\n",
    "        random_img=images['random']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: torch.nn.Module, device: torch.device, test_loader: torch.utils.data.DataLoader, oracle: Attack, logic: Logic, constraint: Constraint) -> EpochInfoTest:\n",
    "    correct, constr_acc, constr_sec = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "    avg_pred_loss, avg_constr_loss, avg_random_loss = torch.tensor(0., device=device), torch.tensor(0., device=device), torch.tensor(0., device=device)\n",
    "\n",
    "    record_vacuously_true = isinstance(constraint, EvenOddConstraint) or isinstance(constraint, ClassSimilarityConstraint)\n",
    "\n",
    "    if record_vacuously_true:\n",
    "        vacuously_true = torch.zeros(2 if isinstance(constraint, EvenOddConstraint) else 10, device=device)\n",
    "\n",
    "    total_samples = 0\n",
    "\n",
    "    images = { 'input': None, 'random': None, 'adv': None}\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for _, (data, target) in enumerate(test_loader, start=1):\n",
    "        inputs, labels = data.to(device), target.to(device)\n",
    "        total_samples += inputs.size(0)\n",
    "        print(\"1\")\n",
    "        with torch.no_grad():\n",
    "            # forward pass for prediction accuracy\n",
    "            outputs = model(inputs)\n",
    "            avg_pred_loss += F.cross_entropy(outputs, labels, reduction='sum')\n",
    "            pred = outputs.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "            # get random samples (no grad)\n",
    "            random = oracle.uniform_random_sample(inputs)\n",
    "        print(\"2\")\n",
    "        # get adversarial samples (requires grad)\n",
    "        adv = oracle.attack(model, inputs, labels, logic, constraint)\n",
    "        print(\"3\")\n",
    "        # forward passes for constraint accuracy (constraint satisfaction on random samples) + constraint security (constraint satisfaction on adversarial samples)\n",
    "        with torch.no_grad():\n",
    "            loss_random, sat_random = constraint.eval(model, inputs, random, labels, logic, reduction='sum')\n",
    "            loss_adv, sat_adv = constraint.eval(model, inputs, adv, labels, logic, reduction='sum')\n",
    "\n",
    "            if record_vacuously_true:\n",
    "                vacuously_true += constraint.get_vacuously_true(model, adv)\n",
    "\n",
    "            constr_acc += sat_random\n",
    "            constr_sec += sat_adv\n",
    "\n",
    "            avg_random_loss += loss_random\n",
    "            avg_constr_loss += loss_adv\n",
    "        print(\"4\")\n",
    "        # save one original image, random sample, and adversarial sample image (for debugging, inspecting attacks)\n",
    "        i = np.random.randint(0, inputs.size(0) - 1)\n",
    "        images['input'], images['random'], images['adv'] = inputs[i], random[i], adv[i]\n",
    "\n",
    "    return EpochInfoTest(\n",
    "        pred_acc=correct.item() / total_samples, \n",
    "        constr_acc=constr_acc.item() / total_samples,\n",
    "        constr_sec=constr_sec.item() / total_samples,\n",
    "        pred_loss=avg_pred_loss.item() / total_samples,\n",
    "        random_loss=avg_random_loss.item() / total_samples,\n",
    "        constr_loss=avg_constr_loss.item() / total_samples,\n",
    "        input_img=images['input'],\n",
    "        adv_img=images['adv'],\n",
    "        random_img=images['random'],\n",
    "        vacuously_true=(vacuously_true / total_samples) if record_vacuously_true else -1.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = TorchBackend()\n",
    "\n",
    "logics: list[Logic] = [\n",
    "    DL2(backend),\n",
    "    GoedelFuzzyLogic(backend),\n",
    "    KleeneDienesFuzzyLogic(backend),\n",
    "    LukasiewiczFuzzyLogic(backend),\n",
    "    ReichenbachFuzzyLogic(backend),\n",
    "    GoguenFuzzyLogic(backend),\n",
    "    ReichenbachSigmoidalFuzzyLogic(backend),\n",
    "    YagerFuzzyLogic(backend)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = [3,3,3,3,3,3,2,3,3,4,4,1,0,0,0,4,4,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,5,5,5,5,5,5,5,5,2,2]\n",
    "GROUP_NAMES = [\"Unique Signs\",\"Danger Signs\",\"Derestriction Signs\",\"Speed Limit Signs\",\"Other Prohibitory Signs\",\"Mandatory Signs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N = 32\n",
    "batch_size = 128\n",
    "n_classes = 12\n",
    "epochs = 30\n",
    "kwargs = {\"batch_size\": batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_data\n",
    "PATH,LABELS,normalise,GROUPS,GROUP_NAMES,n_classes,train_loader,test_loader = get_data(32,128)\n",
    "mean = 0.3211\n",
    "std = 0.2230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.backends.cudnn.deterministic = False #True\n",
    "    torch.backends.cudnn.benchmark = True #False\n",
    "\n",
    "    kwargs.update({ 'num_workers': 4, 'pin_memory': True })\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        x = torch.zeros((64,1,_N,_N))\n",
    "\n",
    "        self.activation = torch.nn.functional.relu\n",
    "\n",
    "        self.pool = torch.nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1,6,5)\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(x.shape[1],16,5)\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        self.dense1 = torch.nn.Linear(x.shape[1],120)\n",
    "        x = self.activation(self.dense1(x))\n",
    "        self.dense2 = torch.nn.Linear(x.shape[1],80)\n",
    "        x = self.activation(self.dense2(x))\n",
    "        self.final = torch.nn.Linear(x.shape[1],n_classes)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.activation(self.dense1(x))\n",
    "        x = self.activation(self.dense2(x))\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constraint.eps=0.062745101749897\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logic = logics[0] # need some logic loss for oracle even for baseline\n",
    "is_baseline = True\n",
    "\n",
    "epsilon = 16 / 255\n",
    "delta = 0.02\n",
    "\n",
    "constraint = MyConstraint(device,epsilon)\n",
    "print(f'constraint.eps={constraint.eps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "\n",
    "pgd_iterations = 20\n",
    "pgd_restarts = 10\n",
    "oracle = APGD(device, pgd_iterations, pgd_restarts, mean, std, constraint.eps)\n",
    "oracle_test = APGD(device, pgd_iterations * 2, pgd_restarts, mean, std, constraint.eps)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "grad_norm = GradNorm(model, device, optimizer, lr=0.001, alpha=0.12, initial_dl_weight=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n",
      "#model parameters: 61344\n"
     ]
    }
   ],
   "source": [
    "folder = \"abcd\"\n",
    "folder_name = \"abcd\"\n",
    "file_name = \"abcd/test\"\n",
    "report_file_name = f'{file_name}.csv'\n",
    "model_file_name = f'{file_name}.onnx'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "def save_imgs(info: EpochInfoTrain | EpochInfoTest, epoch):\n",
    "    return\n",
    "print(f'using device {device}')\n",
    "print(f'#model parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "with_extra_info = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAA\n",
      "BBB\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CCCC\n",
      "Epoch 0/30 \t TRAIN \t P-Acc: 0.00 \t C-Acc: 0.00\t C-Sec: 0.00\t P-Loss: 0.00\t R-Loss: 0.00\t DL-Loss: 0.00\t Time (Train) [s]: 0.0\n",
      "===\n",
      "AAAA\n",
      "Batch: 0\n",
      "Batch: 1\n",
      "Batch: 2\n",
      "Batch: 3\n",
      "Batch: 4\n",
      "Batch: 5\n",
      "Batch: 6\n",
      "Batch: 7\n",
      "Batch: 8\n",
      "Batch: 9\n",
      "Batch: 10\n",
      "Batch: 11\n",
      "Batch: 12\n",
      "Batch: 13\n",
      "Batch: 14\n",
      "Batch: 15\n",
      "Batch: 16\n",
      "Batch: 17\n",
      "Batch: 18\n",
      "Batch: 19\n",
      "Batch: 20\n",
      "Batch: 21\n",
      "Batch: 22\n",
      "Batch: 23\n",
      "Batch: 24\n",
      "Batch: 25\n",
      "Batch: 26\n",
      "Batch: 27\n",
      "Batch: 28\n",
      "Batch: 29\n",
      "Batch: 30\n",
      "Batch: 31\n",
      "Batch: 32\n",
      "Batch: 33\n",
      "Batch: 34\n",
      "Batch: 35\n",
      "Batch: 36\n",
      "Batch: 37\n",
      "Batch: 38\n",
      "Batch: 39\n",
      "Batch: 40\n",
      "Batch: 41\n",
      "Batch: 42\n",
      "Batch: 43\n",
      "Batch: 44\n",
      "Batch: 45\n",
      "Batch: 46\n",
      "Batch: 47\n",
      "Batch: 48\n",
      "Batch: 49\n",
      "Batch: 50\n",
      "Batch: 51\n",
      "Batch: 52\n",
      "Batch: 53\n",
      "Batch: 54\n",
      "Batch: 55\n",
      "Batch: 56\n",
      "Batch: 57\n",
      "Batch: 58\n",
      "Batch: 59\n",
      "Batch: 60\n",
      "Batch: 61\n",
      "Batch: 62\n",
      "Batch: 63\n",
      "Batch: 64\n",
      "Batch: 65\n",
      "Batch: 66\n",
      "Batch: 67\n",
      "Batch: 68\n",
      "Batch: 69\n",
      "Batch: 70\n",
      "Batch: 71\n",
      "Batch: 72\n",
      "Batch: 73\n",
      "GradNorm weights=tensor([1.0615, 0.9385])\n",
      "Epoch 1/30 \t TRAIN \t P-Acc: 0.23 \t C-Acc: 0.04\t C-Sec: 0.03\t P-Loss: 2.48\t R-Loss: 0.08\t DL-Loss: 0.14\t Time (Train) [s]: 2905.8\n",
      "BBB\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "with open(report_file_name, 'w', buffering=1, newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    csvfile.write(f'#{sys.argv}\\n')\n",
    "    writer.writerow(['Epoch', 'Train-P-Loss', 'Train-R-Loss', 'Train-C-Loss', 'Train-P-Loss-Weight', 'Train-C-Loss-Weight', 'Train-P-Acc', 'Train-C-Acc', 'Train-C-Sec', 'Test-P-Acc', 'Test-C-Acc', 'Test-C-Sec', 'Train-Time', 'Test-Time'])\n",
    "\n",
    "    for epoch in range(0, epochs + 1):\n",
    "        start = time.time()\n",
    "        print(\"AAAA\")\n",
    "        if epoch > 0:\n",
    "            with_dl = True # (epoch > args.delay) and (not is_baseline)\n",
    "            train_info = train(model, device, train_loader, optimizer, oracle, grad_norm, logic, constraint, with_dl)\n",
    "            train_time = time.time() - start\n",
    "\n",
    "            save_imgs(train_info, epoch)\n",
    "\n",
    "            print(f'Epoch {epoch}/{epochs} \\t TRAIN \\t P-Acc: {train_info.pred_acc:.2f} \\t C-Acc: {train_info.constr_acc:.2f}\\t C-Sec: {train_info.constr_sec:.2f}\\t P-Loss: {train_info.pred_loss:.2f}\\t R-Loss: {train_info.random_loss:.2f}\\t DL-Loss: {train_info.constr_loss:.2f}\\t Time (Train) [s]: {train_time:.1f}')\n",
    "        else:\n",
    "            train_info = EpochInfoTrain(0., 0., 0., 0., 0., 0., 1., 1., None, None, None)\n",
    "            train_time = 0.\n",
    "        print(\"BBB\")\n",
    "        test_info = test(model, device, test_loader, oracle_test, logic, constraint)\n",
    "        test_time = time.time() - start - train_time\n",
    "        print(\"CCCC\")\n",
    "        save_imgs(test_info, epoch)\n",
    "\n",
    "        writer.writerow([epoch, \\\n",
    "                            train_info.pred_loss, train_info.random_loss, train_info.constr_loss, train_info.pred_loss_weight, train_info.constr_loss_weight, train_info.pred_acc, train_info.constr_acc, train_info.constr_sec, \\\n",
    "                            test_info.pred_acc, test_info.constr_acc, test_info.constr_sec, \\\n",
    "                            train_time, test_time] \\\n",
    "                        + ([v.item() for v in test_info.vacuously_true] if with_extra_info else []))\n",
    "        \n",
    "        if with_extra_info:\n",
    "            print(f'impl vacuously true=[{\" \".join([f\"{x:.2f}\" for x in test_info.vacuously_true])}]')\n",
    "\n",
    "        print(f'Epoch {epoch}/{epochs} \\t TRAIN \\t P-Acc: {train_info.pred_acc:.2f} \\t C-Acc: {train_info.constr_acc:.2f}\\t C-Sec: {train_info.constr_sec:.2f}\\t P-Loss: {train_info.pred_loss:.2f}\\t R-Loss: {train_info.random_loss:.2f}\\t DL-Loss: {train_info.constr_loss:.2f}\\t Time (Train) [s]: {train_time:.1f}')\n",
    "        print(f'===')\n",
    "torch.save(model.state_dict(),f\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_constraint(self, model: torch.nn.Module, _inputs: None, adv: torch.Tensor, _labels: None) -> Callable[[Logic], torch.Tensor]:\n",
    "        predictions = model(adv)\n",
    "        GROUPS = [1, 1, 2, 2, 1, 0, 0, 0, 2, 2, 0, 1]\n",
    "        batch_size = len(adv)\n",
    "        in_group = torch.zeros((batch_size,4)).to(self.device)\n",
    "        out_of_group = torch.zeros((batch_size,8)).to(self.device)\n",
    "        \n",
    "        for batch_index,pred in enumerate(predictions):\n",
    "            correct_group = GROUPS[_labels[batch_index]]\n",
    "            in_counter = 0\n",
    "            out_counter = 0\n",
    "            for label,group in enumerate(GROUPS):\n",
    "                if group == correct_group:\n",
    "                    in_group[batch_index,in_counter] = pred[label]\n",
    "                    in_counter += 1\n",
    "                else:\n",
    "                    out_of_group[batch_index,out_counter] = pred[label]\n",
    "                    out_counter += 1\n",
    "        return lambda l: reduce(\n",
    "                l.AND,\n",
    "                [\n",
    "                    l.LEQ(out_of_group[:,j], in_group[:,i]) for i in range(4) for j in range(8)\n",
    "                ]\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
