{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchsummary import summary\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N = 32\n",
    "batch_size = 128\n",
    "n_classes = 43\n",
    "torch.set_float32_matmul_precision('high')\n",
    "mean = 0.3211\n",
    "std = 0.2230\n",
    "epochs = 100\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import get_data\n",
    "PATH,LABELS,normalise,GROUPS,GROUP_NAMES,n_classes,train_loader,test_loader = get_data(_N,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(img): # convert to unormalized form for viewing\n",
    "    return (img * std + mean).permute(1,2,0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0, 3: 1, 5: 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_to_keep = {2,3,5}\n",
    "{old : new for new,old in enumerate(groups_to_keep)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Unique Signs', 'Derestriction Signs', 'Other Prohibitory Signs']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GROUP_MATRIX = [[int(group == i) for group in GROUPS] for i in range(3)]\n",
    "\n",
    "print(\",\\n\".join(map(str,GROUP_MATRIX)))\n",
    "\n",
    "GROUP_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [128, 6, 28, 28]             156\n",
      "         AvgPool2d-2           [128, 6, 14, 14]               0\n",
      "            Conv2d-3          [128, 16, 10, 10]           2,416\n",
      "         AvgPool2d-4            [128, 16, 5, 5]               0\n",
      "            Linear-5                 [128, 120]          48,120\n",
      "            Linear-6                  [128, 80]           9,680\n",
      "            Linear-7                  [128, 12]             972\n",
      "================================================================\n",
      "Total params: 61,344\n",
      "Trainable params: 61,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 7.90\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 8.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        x = torch.zeros((batch_size,1,_N,_N))\n",
    "\n",
    "        self.activation = torch.nn.functional.relu\n",
    "\n",
    "        self.pool = torch.nn.AvgPool2d(2,2)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1,6,5)\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(x.shape[1],16,5)\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        self.dense1 = torch.nn.Linear(x.shape[1],120)\n",
    "        x = self.activation(self.dense1(x))\n",
    "        self.dense2 = torch.nn.Linear(x.shape[1],80)\n",
    "        x = self.activation(self.dense2(x))\n",
    "        self.final = torch.nn.Linear(x.shape[1],n_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        x = self.activation(self.dense1(x))\n",
    "        x = self.activation(self.dense2(x))\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model = Model().to(device)\n",
    "summary(model,(1,32,32),batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_group = [[5,6,7,10],[0,1,4,11],[2,3,8,9]]\n",
    "out_of_group = [[0,1,2,3,4,8,9,11],[2,3,5,6,7,8,9,10],[0,1,4,5,6,7,10,11]]\n",
    "GROUP_MATRIX = torch.tensor([\n",
    "    [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
    "    ])\n",
    "\n",
    "def constraint_accuracy(preds,labels): # CA calculated for a batch\n",
    "    total = 0\n",
    "    for pred,label in zip(preds,labels):\n",
    "        group = GROUPS[label]\n",
    "        unsatisfied = False\n",
    "        for label_in in in_group[group]:\n",
    "            for label_out in out_of_group[group]:\n",
    "                if pred[label_out] > pred[label_in]:\n",
    "                    unsatisfied = True\n",
    "                    break\n",
    "            if unsatisfied:\n",
    "                break\n",
    "        if not unsatisfied:\n",
    "            total += 1\n",
    "    return total / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_train(model,loss_func,optimiser,epochs):\n",
    "    early = EarlyStopping(5)\n",
    "    for epoch in range(epochs):\n",
    "        ca = 0\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            groups = labels_to_groups(labels).to(device)\n",
    "            images = images.to(device)\n",
    "\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            preds = model(images)\n",
    "\n",
    "            loss = loss_func(preds, groups)\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "            ca += constraint_accuracy(preds,labels)\n",
    "        \n",
    "        validation_loss = constraint_validation_loss(model,loss_func)\n",
    "        print(f\"Epoch {epoch+1} --- Training Loss {total_loss / len(train_loader):.3f} --- Validation Loss {validation_loss:.3f} --- Constraint Accuracy {ca / len(train_loader):.3f}\")\n",
    "        if early.should_stop_early(validation_loss):\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "def constraint_validation_loss(model,loss_func):\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            groups = labels_to_groups(labels).to(device)\n",
    "            preds = model(images)\n",
    "            loss += loss_func(preds,groups).item()\n",
    "    return loss / len(test_loader)\n",
    "\n",
    "def labels_to_groups(labels):\n",
    "    # takes a batch of labels\n",
    "    # returns one hot encoding of group stuff...\n",
    "    batch_size = len(labels)\n",
    "    out = torch.zeros((batch_size,12))\n",
    "    for i,label in enumerate(labels):\n",
    "        out[i] = GROUP_MATRIX[GROUPS[label]]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pgd_attack(model,images,groups,loss_func,epsilon,iterations,decay_rate,learning_rate,momentum_decay):\n",
    "    adversarial = denormalise(images)\n",
    "    lower_bound = adversarial - epsilon\n",
    "    upper_bound = adversarial + epsilon\n",
    "    \n",
    "    decay = torch.logspace(decay_rate,1,iterations,2)\n",
    "    decay = decay / decay[0]\n",
    "    decay *= learning_rate\n",
    "    \n",
    "    momentum = torch.zeros(images.shape).to(device)\n",
    "\n",
    "    for alpha in decay:\n",
    "        normalised = normalise(adversarial)\n",
    "        normalised.requires_grad = True\n",
    "        model.zero_grad()\n",
    "        pred = model(normalised)\n",
    "        loss = loss_func(pred,groups)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        perturbations = torch.sign(normalised.grad.data)\n",
    "        \n",
    "        adversarial += (perturbations + momentum) * alpha\n",
    "\n",
    "        momentum = momentum * momentum_decay + (1 - momentum_decay) * perturbations\n",
    "\n",
    "        adversarial = torch.clip(adversarial,lower_bound, upper_bound)\n",
    "        adversarial = torch.clip(adversarial,0,1)\n",
    "\n",
    "    return normalise(adversarial)\n",
    "\n",
    "\n",
    "\n",
    "normalise.to(device)\n",
    "\n",
    "@torch.compile\n",
    "def denormalise(images):\n",
    "    return images * std + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,epsilon):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    cs = 0\n",
    "\n",
    "    for images,lbls in test_loader:\n",
    "        cs += constraint_security(images,lbls,model,epsilon,loss_func)\n",
    "\n",
    "        labels.extend(lbls.numpy())\n",
    "        \n",
    "        images = images.to(device)\n",
    "        preds = model(images)\n",
    "        predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "        \n",
    "            \n",
    "    cs /= len(test_loader)\n",
    "            \n",
    "    labels = np.array(labels)\n",
    "    predictions = np.array(predictions)\n",
    "    pred_class = np.argmax(predictions,axis=1)\n",
    "    precision = precision_score(labels, pred_class, average=\"weighted\")\n",
    "    recall = recall_score(labels, pred_class, average=\"weighted\")\n",
    "    f1 = f1_score(labels, pred_class, average=\"weighted\")\n",
    "    print(f'Precision (macro): {precision:.4f}')\n",
    "    print(f'Recall (macro): {recall:.4f}')\n",
    "    print(f'F1-score (macro): {f1:.4f}')\n",
    "    print(f\"Constraint Security: {cs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_security(images,labels,model,epsilon,loss_func):\n",
    "    decay_rate = 6\n",
    "    learning_rate = 40 / 255\n",
    "    momentum_decay = 0.8\n",
    "    iterations = 40\n",
    "    groups = labels_to_groups(labels).to(device)\n",
    "\n",
    "    adv = pgd_attack(model,images.to(device),groups,loss_func,epsilon,iterations,decay_rate,learning_rate,momentum_decay)\n",
    "    pred = model(adv)\n",
    "    return constraint_accuracy(pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (macro): 0.3155\n",
      "Recall (macro): 0.2479\n",
      "F1-score (macro): 0.2554\n",
      "Constraint Security: 0.8797\n"
     ]
    }
   ],
   "source": [
    "epsilon = 5 / 255\n",
    "loss_func = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "model = Model().to(device)\n",
    "model.load_state_dict(torch.load(\"models/constraint_only_10_eps.pth\"))\n",
    "evaluate(model,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (macro): 0.9917\n",
      "Recall (macro): 0.9915\n",
      "F1-score (macro): 0.9915\n",
      "Constraint Security: 0.7061\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "model.load_state_dict(torch.load(\"models/hybrid_10_eps.pth\"))\n",
    "evaluate(model,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (macro): 0.9878\n",
      "Recall (macro): 0.9877\n",
      "F1-score (macro): 0.9877\n",
      "Constraint Security: 0.0021\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "model.load_state_dict(torch.load(\"models/superclass_base.pth\"))\n",
    "evaluate(model,epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
