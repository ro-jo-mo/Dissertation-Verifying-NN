{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### Import the relevant libraries ###\n",
    "#####################################\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"dataset\") / \"GTSRB\"\n",
    "PATH_TRAIN = PATH / \"Training\"\n",
    "\n",
    "def load_dataset():\n",
    "    train_directories = [PATH_TRAIN / subdir for subdir in os.listdir(PATH_TRAIN) if os.path.isdir(PATH_TRAIN / subdir)]\n",
    "    #Test data is unlabelled??? -> Just split off training data for testing\n",
    "    data = [[(cv2.cvtColor(cv2.imread(path / img), cv2.COLOR_BGR2RGB),path.name) for img in os.listdir(path) if img.endswith(\".ppm\")] for path in train_directories]\n",
    "    X = [[img[0] for img in row] for row in data]\n",
    "    Y = [[img[1] for img in row] for row in data]\n",
    "    #Flatten 2d structure   \n",
    "    X = [img for row in X for img in row]\n",
    "    Y = np.array([label for row in Y for label in row])\n",
    "    return (X,Y)\n",
    "(X,Y) = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image(img):\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off') \n",
    "    plt.show()\n",
    "show_image(X[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EagerTensor object has no attribute 'astype'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Transform images to same size\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m show_image(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m(np\u001b[38;5;241m.\u001b[39muint8))\n",
      "File \u001b[0;32m~/code/Project/projectenv/lib/python3.10/site-packages/tensorflow/python/framework/tensor.py:255\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m    252\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[0;32m--> 255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124m      If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124m      tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m    260\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: EagerTensor object has no attribute 'astype'. \n        If you are looking for numpy-related methods, please run the following:\n        tf.experimental.numpy.experimental_enable_numpy_behavior()\n      "
     ]
    }
   ],
   "source": [
    "#Transform images to same size\n",
    "t = tf.image.resize(X[0],[64,64])\n",
    "#Normalise data\n",
    "normalisation_layer = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00027', '00013', '00004', '00007', '00030', '00039', '00035', '00005', '00018', '00016', '00020', '00008', '00034', '00009', '00010', '00036', '00026', '00019', '00015', '00040', '00006', '00032', '00012', '00042', '00014', '00021', '00002', '00037', '00003', '00017', '00029', '00024', '00041', '00023', '00022', '00033', '00031', '00025', '00001', '00028', '00011', '00038', '00000']\n",
      "Found 0 files belonging to 43 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory dataset/GTSRB/Training. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m path_train \u001b[38;5;241m=\u001b[39m path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(path_train))\n\u001b[0;32m----> 4\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/code/Project/projectenv/lib/python3.10/site-packages/keras/src/utils/image_dataset_utils.py:329\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    325\u001b[0m image_paths, labels \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    326\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    334\u001b[0m dataset \u001b[38;5;241m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    335\u001b[0m     image_paths\u001b[38;5;241m=\u001b[39mimage_paths,\n\u001b[1;32m    336\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m    348\u001b[0m )\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: No images found in directory dataset/GTSRB/Training. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### Visualise some examples ###\n",
    "###############################\n",
    "\n",
    "def display_some_examples(examples, labels, n_examples):\n",
    "    plt.figure(figsize=(17,6))\n",
    "\n",
    "    for i in range(n_examples):\n",
    "        idx = np.random.randint(0, examples.shape[0] - 1)\n",
    "        img = examples[idx]\n",
    "        label = labels[idx]\n",
    "\n",
    "        plt.subplot(3, 10, i + 1)\n",
    "        plt.title(str(label))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_some_examples(X_train, y_train, n_examples=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### Visualise some features ###\n",
    "###############################\n",
    "\n",
    "def plot_random_pixels_from_mnist(examples, labels, num_subplots=30):\n",
    "    # Flatten the examples dataset (assumed to be in shape (num_samples, 28, 28))\n",
    "    x_train_flattened = examples.reshape(examples.shape[0], 28 * 28)\n",
    "\n",
    "    # Randomly select 'num_subplots' features (pixels) from 0 to 783\n",
    "    random_pixel_indices = np.random.choice(28 * 28, num_subplots, replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    for i, pixel_idx in enumerate(random_pixel_indices):\n",
    "        plt.subplot(5, 6, i + 1)  # Create a 5x6 grid of subplots\n",
    "        \n",
    "        # Get the color intensities for the selected pixel across all images\n",
    "        pixel_values = x_train_flattened[:, pixel_idx]\n",
    "        \n",
    "        # Plot the pixel values on the x-axis and the class labels (labels) on the y-axis\n",
    "        plt.scatter(pixel_values, labels, alpha=0.5, s=1)\n",
    "        \n",
    "        plt.title(f'Pixel {pixel_idx}')\n",
    "        plt.xlabel('Color Intensity (0-255)')\n",
    "        plt.ylabel('Class Label (0-9)')\n",
    "        plt.xlim([0, 255])  # Color intensity is between 0 and 255\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage assuming x_train and y_train are loaded MNIST dataset arrays\n",
    "plot_random_pixels_from_mnist(X_train, y_train, num_subplots=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **BASE TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Set some variables ###\n",
    "##########################\n",
    "\n",
    "input_size = 28 * 28\n",
    "batch_size = 64\n",
    "epochs = 6\n",
    "n_classes = 10\n",
    "epsilon = 0.3\n",
    "alpha = 0.1\n",
    "num_iter = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "### Pre-process the data ###\n",
    "############################\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], input_size)\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], input_size)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "### Define the model ###\n",
    "########################\n",
    "\n",
    "def get_model(input_size):\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "    model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(input_size,), name='input_features'),\n",
    "            tf.keras.layers.Dense(128, activation='relu', kernel_initializer=initializer, name='dense_1'),\n",
    "            tf.keras.layers.Dense(10, activation='linear', kernel_initializer=initializer, name='output_layer')\n",
    "        ])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### Train a base model ###\n",
    "##########################\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "accuracy_fn = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "model_base = get_model(input_size)\n",
    "model_base.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy_fn])\n",
    "model_base.fit(train_dataset, epochs=epochs, validation_data=test_dataset,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "### Define the precision, recall, F1 and ROC curve function ###\n",
    "###############################################################\n",
    "\n",
    "def print_metrics(model, x, y, c):\n",
    "    # Get predicted probabilities for all classes\n",
    "    y_pred_prob = model.predict(x)\n",
    "\n",
    "    # Get predicted class labels (highest probability class)\n",
    "    y_pred_class = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score (using macro average)\n",
    "    precision = precision_score(y, y_pred_class, average='macro')\n",
    "    recall = recall_score(y, y_pred_class, average='macro')\n",
    "    f1 = f1_score(y, y_pred_class, average='macro')\n",
    "\n",
    "    # Display the macro/micro/weighted average metrics\n",
    "    print(f'Precision (macro): {precision:.4f}')\n",
    "    print(f'Recall (macro): {recall:.4f}')\n",
    "    print(f'F1-score (macro): {f1:.4f}')\n",
    "\n",
    "    # Binarize the output (needed for multiclass ROC)\n",
    "    # This turns the class labels into a one-vs-rest binary format\n",
    "    y_test_bin = label_binarize(y, classes=np.arange(c))\n",
    "\n",
    "    # Compute ROC curve and AUC for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(c):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "        roc_auc[i] = roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "\n",
    "    # Plot the ROC curve for each class\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for i in range(c):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Dashed diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) for Each Class')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "### Calculate precision, recall, F1 and ROC curve ###\n",
    "#####################################################\n",
    "\n",
    "print_metrics(model_base, X_test, y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "### Define the PGD attack function ###\n",
    "######################################\n",
    "\n",
    "def pgd_attack(model, x, y, epsilon, alpha, num_iter):\n",
    "    \"\"\"Perform PGD attack on a batch of images.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model.\n",
    "        x: Input images (batch).\n",
    "        y: True labels (batch).\n",
    "        epsilon: Maximum perturbation.\n",
    "        alpha: Step size for each iteration.\n",
    "        num_iter: Number of PGD iterations.\n",
    "\n",
    "    Returns:\n",
    "        Adversarial examples.\n",
    "    \"\"\"\n",
    "    # Make a copy of the input to avoid modifying the original data\n",
    "    x_adv = tf.identity(x)\n",
    "\n",
    "    # Iterate PGD for num_iter steps\n",
    "    for i in range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_adv)  # Watch x_adv for gradient computation\n",
    "            predictions = model(x_adv)  # Forward pass\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y, predictions)  # Loss w.r.t. true label\n",
    "\n",
    "        # Compute the gradients of the loss w.r.t. the input\n",
    "        gradients = tape.gradient(loss, x_adv)\n",
    "        \n",
    "        # Perform gradient ascent step in the direction that maximizes the loss\n",
    "        perturbations = tf.sign(gradients)  # Use the sign of the gradients (FGSM-like step)\n",
    "        x_adv = x_adv + alpha * perturbations  # Update the adversarial example\n",
    "        \n",
    "        # Project the adversarial example to ensure it's within epsilon-ball of the original image\n",
    "        x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n",
    "        \n",
    "        # Ensure the adversarial examples are within the valid input range [0, 1]\n",
    "        x_adv = tf.clip_by_value(x_adv, 0.0, 1.0)\n",
    "    \n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "### Define the function to visualize the original and adversarial images ###\n",
    "############################################################################\n",
    "\n",
    "def original_vs_adversarial_images(x_og, y_og, x_adv, y_pred):\n",
    "    plt.figure(figsize=(17, 4))\n",
    "\n",
    "    # Counter for how many images to display\n",
    "    display_count = 0\n",
    "\n",
    "    for i in range(len(x_og)):\n",
    "        # Check if the class changes after the attack\n",
    "        if y_og[i] != y_pred[i]:\n",
    "            # Original images (reshape from (28, 28, 1) to (28, 28))\n",
    "            original_image = x_og[i].reshape(28, 28)\n",
    "            \n",
    "            # Adversarial images (reshape from (28, 28, 1) to (28, 28))\n",
    "            adversarial_image = x_adv[i].numpy().reshape(28, 28)\n",
    "\n",
    "            # Plot original images\n",
    "            plt.subplot(2, 10, display_count + 1)\n",
    "            plt.imshow(original_image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Orig: {y_og[i]}')\n",
    "\n",
    "            # Plot adversarial images\n",
    "            plt.subplot(2, 10, display_count + 11)\n",
    "            plt.imshow(adversarial_image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Adv: {y_pred[i]}')\n",
    "\n",
    "            # Increment the display counter\n",
    "            display_count += 1\n",
    "            \n",
    "            # Stop after displaying 10 images\n",
    "            if display_count == 10:\n",
    "                break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "### Attack the model using PGD and visualize the original and adversarial images ###\n",
    "####################################################################################\n",
    "\n",
    "# Test the PGD attack\n",
    "x_test_sample = X_test\n",
    "y_test_sample = y_test\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv = pgd_attack(model_base, x_test_sample, y_test_sample, epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "\n",
    "# Evaluate the model on the adversarial examples\n",
    "y_pred_adv = np.argmax(model_base.predict(x_test_adv), axis=1)\n",
    "accuracy_adv = np.mean(y_pred_adv == y_test_sample)\n",
    "\n",
    "print(f'Accuracy on adversarial examples: {accuracy_adv:.4f}')\n",
    "original_vs_adversarial_images(x_test_sample, y_test_sample, x_test_adv, y_pred_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# **ADVERSARIAL TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "### Define the adversarial training function ###\n",
    "################################################\n",
    "\n",
    "def adversarial_training(model, train_dataset, optimizer, loss_fn, epsilon, alpha, num_iter, epochs):\n",
    "    \"\"\"\n",
    "    Performs adversarial training with PGD adversarial examples.\n",
    "    \n",
    "    Args:\n",
    "    model: The model to train.\n",
    "    train_dataset: A TensorFlow dataset for training.\n",
    "    optimizer: The optimizer for model training.\n",
    "    loss_fn: Loss function to use.\n",
    "    epsilon: Maximum perturbation for PGD (epsilon).\n",
    "    alpha: Step size for PGD.\n",
    "    num_iter: Number of PGD iterations for generating adversarial examples.\n",
    "    epochs: Number of training epochs.\n",
    "    \n",
    "    Returns:\n",
    "    model: The trained model.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()  # Record start time for the epoch\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        # Accuracy metric for the epoch\n",
    "        train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        \n",
    "        # Training loop over batches\n",
    "        for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate adversarial examples using PGD\n",
    "                x_adv_batch = pgd_attack(model, x_batch, y_batch, epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "                \n",
    "                # Combine original and adversarial examples for training\n",
    "                combined_x = tf.concat([x_batch, x_adv_batch], axis=0)\n",
    "                combined_y = tf.concat([y_batch, y_batch], axis=0)\n",
    "                \n",
    "                # Forward pass\n",
    "                logits = model(combined_x, training=True)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = loss_fn(combined_y, logits)\n",
    "            \n",
    "            # Backpropagation\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # Update training accuracy metric\n",
    "            train_acc_metric.update_state(combined_y, logits)\n",
    "\n",
    "        # End of epoch: calculate and print accuracy and epoch time\n",
    "        train_acc = train_acc_metric.result().numpy()\n",
    "\n",
    "        # Evaluate on test dataset (for validation accuracy)\n",
    "        test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        for x_test_batch, y_test_batch in test_dataset:\n",
    "            test_logits = model(x_test_batch, training=False)\n",
    "            test_acc_metric.update_state(y_test_batch, test_logits)\n",
    "        test_acc = test_acc_metric.result().numpy()\n",
    "\n",
    "        print(f\"Train loss: {loss.numpy():.4f} -|- Train acc: {train_acc:.4f} -|- Test acc: {test_acc:.4f} -|- Time: {(time.time() - start_time):.2f}s\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "### Train an adversarial model ###\n",
    "##################################\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model_adv = get_model(input_size)\n",
    "model_adv = adversarial_training(model_adv, train_dataset, optimizer, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=num_iter, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "### Calculate precision, recall, F1 and ROC curve ###\n",
    "#####################################################\n",
    "\n",
    "print_metrics(model_adv, X_test, y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "### Attack the model using PGD and visualize the original and adversarial images ###\n",
    "####################################################################################\n",
    "\n",
    "# Test the PGD attack\n",
    "x_test_sample_ADV = X_test\n",
    "y_test_sample_ADV = y_test\n",
    "\n",
    "# Generate adversarial examples\n",
    "x_test_adv_ADV = pgd_attack(model_adv, x_test_sample_ADV, y_test_sample_ADV, epsilon=epsilon, alpha=alpha, num_iter=num_iter)\n",
    "\n",
    "# Evaluate the model on the adversarial examples\n",
    "y_pred_adv_ADV = np.argmax(model_adv.predict(x_test_adv_ADV), axis=1)\n",
    "accuracy_adv_ADV = np.mean(y_pred_adv_ADV == y_test_sample_ADV)\n",
    "\n",
    "print(f'Accuracy on adversarial examples: {accuracy_adv_ADV:.4f}')\n",
    "original_vs_adversarial_images(x_test_sample_ADV, y_test_sample_ADV, x_test_adv_ADV, y_pred_adv_ADV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
